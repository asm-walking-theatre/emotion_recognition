{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J-z7SNu-y_vU"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import dlib\n",
    "import math\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oc7xfvr2FvMZ"
   },
   "outputs": [],
   "source": [
    "#This code cell changes with a given model\n",
    "emotion_list = ['Happy','Anger','Disgust','Fear','Sad','Surprise','Contempt']\n",
    "saved_model_file = 'combined6classes(1fold).h5'\n",
    "recog_model = load_model(saved_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p7dRiY7zGFKu"
   },
   "outputs": [],
   "source": [
    "def predict_emotion(emotion_list, image):\n",
    "    '''\n",
    "    Makes predictions on the given image and returns the list of emotions\n",
    "    '''\n",
    "    probs = recog_model.predict(image[:,:,:,np.newaxis])\n",
    "    preds = np.argmax(probs, axis = -1)\n",
    "    emotion = []\n",
    "    for i in range(preds.shape[-1]):\n",
    "        emotion.append(emotion_list[preds[i]])\n",
    "\n",
    "    return emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GlE4AkiBSsy5"
   },
   "outputs": [],
   "source": [
    "def rotate_image(img,angle):\n",
    "    '''\n",
    "    Returns the rotated image with the given angle\n",
    "    '''\n",
    "    rows,cols = img.shape\n",
    "    M = cv2.getRotationMatrix2D(((rows - 1)/2.0,(cols - 1)/2.0) , angle, 1)\n",
    "    rot_img = cv2.warpAffine(img,M,(cols,rows))\n",
    "\n",
    "    return rot_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vHnBfSCcVCsm"
   },
   "outputs": [],
   "source": [
    "def find_angle(point1, point2):\n",
    "    '''\n",
    "    To find angle in degrees for the given two points\n",
    "    '''\n",
    "    angle_r = math.atan((point2[1] - point1[1])/(point2[0] - point1[0])) # angle in radians\n",
    "    angle_d = math.degrees(angle_r)                                      # angle in degrees\n",
    "\n",
    "    return angle_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N0CMveFSZpSq"
   },
   "outputs": [],
   "source": [
    "def eye_centers(landmarks):\n",
    "    '''\n",
    "    To find the eye centers(mean of the 6 landmark points around the eye)\n",
    "    '''\n",
    "\n",
    "    point1 = (np.mean(landmarks[36:42,0]),np.mean(landmarks[36:42,1])) #36-41 are landmark points surrounding right eye\n",
    "    point2 = (np.mean(landmarks[42:48,0]),np.mean(landmarks[42:48,1])) #42-47 are landmark points surrounding left eye\n",
    "\n",
    "    return point1, point2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8fJaxeCb178P"
   },
   "outputs": [],
   "source": [
    "def landmark_array(crop_image, face):\n",
    "    '''\n",
    "    To convert landmarks which are in dlib rectangle object to an ndarray\n",
    "    '''\n",
    "\n",
    "    landmarks = predictor(crop_image, face)\n",
    "    landmark_array = np.zeros((landmarks.num_parts,2))\n",
    "    \n",
    "    for i in range(landmarks.num_parts):\n",
    "        \n",
    "        landmark_array[i,0] = landmarks.part(i).x\n",
    "        landmark_array[i,1] = landmarks.part(i).y\n",
    "\n",
    "    return landmark_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gC6SAiFlEtba"
   },
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zUlto7nGX-uM"
   },
   "outputs": [],
   "source": [
    "def preprocessing(input_image):\n",
    "    '''\n",
    "    The preprocessing involves rotation of the image and image cropping\n",
    "    Arguments :\n",
    "    input_image -- array of images of shape (1,h,w)\n",
    "    Returns :\n",
    "    List of images after preprocessing\n",
    "    '''\n",
    "\n",
    "    preprocessed_faces = []\n",
    "    faces_coords = []\n",
    "\n",
    "    for img in input_image:\n",
    "        \n",
    "        #To detect all the faces in the image\n",
    "        faces = detector(img)\n",
    "\n",
    "        #iterating over each face\n",
    "        for face in faces:\n",
    "            \n",
    "            x1 = face.left() - 100\n",
    "            y1 = face.top() - 100\n",
    "            x2 = face.right() + 100\n",
    "            y2 = face.bottom() + 100\n",
    "            #following is used to form a rectangle around the face\n",
    "            faces_coords.append([(x1+100,y1+100),(x2-100,y2-100)])\n",
    "\n",
    "            #first cropping to reduce unnecessary parts for rotation\n",
    "            crop_image = img[max(y1,0):min(y2,img.shape[0]),\n",
    "                             max(x1,0):min(x2,img.shape[1])]\n",
    "\n",
    "            #As face coords change after cropping\n",
    "            new_faces = detector(crop_image)\n",
    "            for new_face in new_faces:\n",
    "                \n",
    "                #landmark detection\n",
    "                landmarks = landmark_array(crop_image, new_face)\n",
    "\n",
    "                #detect eye cnters\n",
    "                p1, p2 = eye_centers(landmarks)\n",
    "\n",
    "                #find angle \n",
    "                angle = find_angle(p1, p2)\n",
    "\n",
    "                #rotate image\n",
    "                rot_img = rotate_image(crop_image, angle)\n",
    "\n",
    "                #As face coords change after rotation\n",
    "                new_faces2 = detector(rot_img)\n",
    "                for new_face2 in new_faces2:\n",
    "                    \n",
    "                    #find length 'd'\n",
    "                    p1_new, p2_new = eye_centers(landmark_array(rot_img,new_face2))\n",
    "                    d = cv2.norm(np.array(p1_new) - np.array(p2_new))\n",
    "\n",
    "                    #mid point of new eye centers\n",
    "                    d_mid = ((p2_new[0] + p1_new[0])/2.0 , (p2_new[1] + p1_new[1])/2.0)\n",
    "\n",
    "                    #point above line\n",
    "                    x_up = d_mid[0]\n",
    "                    y_up = d_mid[1] - (0.6*d)\n",
    "\n",
    "                    #cropped image\n",
    "                    x_start = int(landmarks[0,0])\n",
    "                    x_end = int(landmarks[16,0])\n",
    "                    y_start = int(y_up)\n",
    "                    y_end = int(landmarks[8,1])\n",
    "\n",
    "                    roi = rot_img[y_start:y_end,x_start:x_end]\n",
    "                    face_roi = cv2.resize(roi,(256,256))\n",
    "\n",
    "                    preprocessed_faces.append(face_roi)\n",
    "\n",
    "    return preprocessed_faces,faces_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AbERjH0noO9V"
   },
   "outputs": [],
   "source": [
    "def normalization(imagedata, mean, std_dev):\n",
    "    '''\n",
    "    To apply Histogram equalization and Z-Square Normalization to the preprocessed images\n",
    "\n",
    "    Arguments :\n",
    "    imagedata -- array of preprocessed images of shape (m,h,w)\n",
    "    mean -- mean of imagedata array\n",
    "    std_dev -- standard deviation of imagedata array\n",
    "\n",
    "    Returns :\n",
    "    array of normalized images of shape (m,48,48)\n",
    "    '''\n",
    "    normalized_images = []\n",
    "    for i in range(imagedata.shape[0]):\n",
    "        \n",
    "        #Histogram Equilization\n",
    "        hist_eqv = cv2.equalizeHist(imagedata[i])\n",
    "\n",
    "        #Z-Square normalization\n",
    "        zsq_norm = ((hist_eqv - mean)/std_dev)\n",
    "\n",
    "        #Resize\n",
    "        resized_image = cv2.resize(zsq_norm, (48,48))\n",
    "        normalized_images.append(resized_image)\n",
    "\n",
    "    return np.array(normalized_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DwABpFJx_1MI"
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print('cannot open the camera!')\n",
    "    exit()\n",
    "\n",
    "while True:\n",
    "    #capture frame by frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # if frame is read correctly ret is True\n",
    "    if not ret:\n",
    "        print(\"can't recieve the frame.Exiting..\")\n",
    "        break\n",
    "    \n",
    "    # operations on the frame come here\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #To make gray as of shape (m,h,w)\n",
    "    img = gray.reshape((1,) + gray.shape)\n",
    "\n",
    "    #Image preprocessing and normalization\n",
    "    image_list,faces_coords = preprocessing(img)\n",
    "\n",
    "    #To neglect the case where face is not detected\n",
    "    if len(image_list) != 0 :\n",
    "        \n",
    "        image = np.array(image_list)\n",
    "        mean, std = image.mean(),image.std()\n",
    "        image = normalization(image, mean, std)\n",
    "        emotion = predict_emotion(emotion_list,\n",
    "                                    image)\n",
    "\n",
    "        for [(x1,y1),(x2,y2)],i in zip(faces_coords,range(len(emotion))):\n",
    "            \n",
    "            cv2.rectangle(frame,(x1,y1),(x2,y2),(0,255,0),3)\n",
    "            cv2.putText(frame,emotion[i],(x1,y1),font,2,(255,255,255),3,\n",
    "                        cv2.LINE_AA)\n",
    "\n",
    "        cv2.imshow('Frame',frame) #In colab this changes to cv2_imshow(frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMXwgGMs5yUeJHsHqOkKnBK",
   "collapsed_sections": [],
   "mount_file_id": "19I4qHSVBs4YKDWQeMgwGhGE3p_KVOA3v",
   "name": "Webcam.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
